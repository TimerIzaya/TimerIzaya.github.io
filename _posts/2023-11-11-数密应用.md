---
layout:     post
title:      重学数据库
subtitle:   
date:       2023-11-11
author:     TimerIzaya
header-img: img/the-first.png
catalog: false
tags:
    - Note

---

# 存储与检索

#### 最简单的数据库

```shell
db_set () {
  echo "$1,$2" >> database
}

db_get () {
  grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}
```

有几点需要注意的地方：

1. `$1 $2`代表两个变量
2. `">"`在shell中代表重定向，会覆盖文件内容，`">>"`代表追加到下一行
3. `"^$1,"`代表`$1,`开头
4.  sed的-e指的是处理字符串，-f是处理文件。
5. sed的`"s/^$1,//"` 含义为：s/ x / y / 替换x为y ，只替换一次。s / x /y /g为全局替换。
6. `tail -n 1` 查到多行只取第一行

因为是追加写，所以虽然简单，但是db_set()写性能确实很好。

但是db_get()就寄了，要遍历查找，所以需要索引。

**索引的意义在于：**使用一些额外的数据结构，不影响数据本身的内容，同时又能加速查询。但是与此同时，索引拖累了写入速度，因为写数据的同时还要写索引，索引总不能顺序写了吧（LSM也不是完全的顺序写），得随机写，所以为了加速查询，写性能也做出了部分牺牲。

## 散列索引

总结这玩意儿，是想锻炼一下评估一个架构的综合能力，不是说散列索引本身具备很大的意义。

### 散列的用处在于：

形成key与value首位地址的KV对，根据key直接去定位到value。

### 散列的大问题在于：

1. Map必须放在内存中，Data可以持久化的时候顺序写保证性能，但是Map没法顺序写。
2. 追加写文件会变得很大，避免大文件出现，需要分段+压缩。
   1. 压缩。之前写过name=xxx了，后面又追加写了name=yyy，需要舍弃name=xxx，压缩空间
   2. 分段。切分文件而已。但是考虑到压缩过的内容，会让段越来越小，所以也要考虑段合并。

### 散列的小问题在于：

1. **文件格式**

   CSV不够快，字符编码要转义，直接用二进制会好很多。

2. **删除记录**

   删除的KV对需要做一个特殊标记，压缩的时候可以舍弃

3. **崩溃恢复**

   由于Map索引是在内存中，崩溃恢复需要遍历所有硬盘文件去二次生成，比较愚蠢。

4. **文件损坏**

   崩溃会导致写了一半的场景出现，需要加校验和。写之前计算校验和hash，崩溃恢复再去检测。

5. **并发性能**

   只能单线程写，多线程读。

6. **范围查询**

   范围查询性能巨差，比如我要找在100到105之间的所有v，那要遍历整个散列表，太蠢了。

### 散列本质：

1. 真实数据是硬盘**顺序写。**

2. 散列索引是内存**随机写。**

   内存的随机写虽然不如顺序写，但绝大部分场景下，也比硬盘中的顺序写快多了。具体快了多少，可以参考存储金字塔的性能。

## SSTable

#### 基于散列索引的优化思路

索引放在内存里必然是不可行的，数据库所在的容器，不管是正常重启、还是断电宕机，只要重启，索引就会丢失，需要遍历所有数据重新生成，非常愚蠢。

所以能不能想办法把索引也给持久化下来？

反正在内存里都是随机写了，你写一个Map(散列)也是写，你写一个Tree也是写，那为什么不写Tree呢？

Tree这个数据结构大类中有一种叫有序树(Ordered Tree)，有序树包含了二叉搜索树、平衡树等，平衡树又包含了AVL树、红黑树、B树等等，那么多树可以用。

#### SSTable索引工作流程

那么SSTable的设计就很简单了：

1. 有数据写入的时候，先写到内存的Tree中。
2. 内存的Tree肯定不可能无限写下去，到了一定阈值就要持久化了，持久化下来的这个文件可以叫做数据段。这个阈值一般设为4M、8M、16M等等（具体设为多少要结合实际的设计，用benchmark反复的测，测出一个最佳的值。另外，这个阈值之所以都是4的倍数，是考虑到硬盘和内存之间的4KB对齐）所以随着时间累积，数据段会越来越多。
3. 有查询请求的时候，先去内存里的Tree查，内存里的Tree没有的话，就去最新的段里面查，最新的段没有，就去其次新的段里查。一直找到为止。
   1. 当定位到某个段时，读出来的这堆数据已经是有序的了，随便二分就找到了。
4. 后台异步起一个线程，定期压缩这些段。

#### 为数不多的致命弱点

​	数据库崩溃这种问题，内存里Tree数据依然丢失，这时候搞一个日志，顺序写进去就行，先写日志，后写Tree。

